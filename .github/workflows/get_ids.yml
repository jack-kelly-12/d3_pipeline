name: Get NCAA IDs

on:
  schedule:
    - cron: "0 */6 * * *" # Runs every 6 hours
  workflow_dispatch: # Keep manual trigger option

concurrency:
  group: ncaa-scraper
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    timeout-minutes: 300 # 5 hour timeout (leaving buffer before next run)

    env:
      GITHUB_PAT: ${{ secrets.PAT }}
      R_LIBS_USER: ${{ github.workspace }}/R/library
      DATA_DIR: data
      SCHEDULES_DIR: data/schedules
      PBP_DIR: data/play_by_play
      STATS_DIR: data/stats

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.10"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas requests beautifulsoup4 tqdm

      - name: Run scraper
        run: |
          python scrapers/get_all_ids.py --data_dir ${{ env.DATA_DIR }}

      - name: Commit and push if changed
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git add data/rosters/master_*.csv
          git diff --quiet && git diff --staged --quiet || (git commit -m "Update roster data [skip ci]" && git push)
